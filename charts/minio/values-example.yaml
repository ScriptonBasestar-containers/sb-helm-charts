# MinIO - Production-Ready Example Configuration
# This is a complete example showing all configuration options
# Copy and customize for your environment

# =============================================================================
# REQUIRED: Set these values before deployment
# =============================================================================
minio:
  rootPassword: ""  # REQUIRED - Generate strong password (min 8 characters)

# =============================================================================
# Deployment Mode Configuration
# =============================================================================
# Choose deployment mode based on your requirements:
# - Standalone: Single server (development/testing)
# - Distributed: 4+ servers with erasure coding (production HA)

# Option 1: Standalone Mode (Development/Testing)
# replicaCount: 1
# minio:
#   mode: standalone
#   drivesPerNode: 1

# Option 2: Distributed Mode (Production HA) - RECOMMENDED
replicaCount: 4  # Minimum 4 nodes for distributed mode
podManagementPolicy: Parallel

updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    partition: 0

# =============================================================================
# MinIO Configuration
# =============================================================================
minio:
  # Deployment mode: standalone or distributed
  mode: distributed  # Use 'standalone' for development

  # Drives per node (distributed mode: 4+ recommended)
  drivesPerNode: 4  # Total drives = replicaCount * drivesPerNode (16 in this example)

  # Root credentials
  rootUser: "admin"
  rootPassword: ""  # SET THIS - Use strong password

  # Alternatively, use existing secret
  # existingSecret: "minio-credentials"
  # rootUserKey: "root-user"
  # rootPasswordKey: "root-password"

  # AWS region
  region: "us-east-1"

  # Console redirect URL (set to ingress URL when using ingress)
  # Example: "https://minio-console.example.com"
  browserRedirectURL: ""

  # Prometheus monitoring
  prometheusAuthType: "public"  # "public" or "jwt"
  prometheusURL: "http://prometheus.monitoring.svc:9090"
  prometheusJobID: "minio-production"

  # Additional server arguments (optional)
  extraArgs: []
    # - --ftp="address=:8021"
    # - --sftp="address=:8022"

# =============================================================================
# Image Configuration
# =============================================================================
image:
  repository: minio/minio
  pullPolicy: IfNotPresent
  tag: ""  # Defaults to chart appVersion

# =============================================================================
# Service Configuration
# =============================================================================
service:
  type: ClusterIP
  api:
    port: 9000
  console:
    port: 9001

# =============================================================================
# Resource Configuration
# =============================================================================
# Production resources (adjust based on workload)
resources:
  limits:
    cpu: 4000m
    memory: 8Gi
  requests:
    cpu: 2000m
    memory: 4Gi

# =============================================================================
# Health Probes
# =============================================================================
livenessProbe:
  httpGet:
    path: /minio/health/live
    port: api
  initialDelaySeconds: 30
  periodSeconds: 20
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /minio/health/ready
    port: api
  initialDelaySeconds: 10
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

startupProbe:
  httpGet:
    path: /minio/health/live
    port: api
  initialDelaySeconds: 0
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 60  # Higher for distributed mode startup

# =============================================================================
# Storage Configuration
# =============================================================================
persistence:
  enabled: true
  storageClass: ""  # Use default or specify (e.g., "fast-ssd")
  accessMode: ReadWriteOnce
  size: 500Gi  # Size per drive (16 drives = 8TB total in distributed mode)
  annotations: {}

# =============================================================================
# High Availability Configuration
# =============================================================================
# Pod Disruption Budget (maintain quorum during updates)
podDisruptionBudget:
  enabled: true
  minAvailable: 3  # Maintain quorum during maintenance (for 4 nodes)
  unhealthyPodEvictionPolicy: "IfHealthyBudget"

# Pod anti-affinity (spread pods across nodes/zones)
affinity:
  podAntiAffinity:
    # HARD requirement: No two MinIO pods on same node
    requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
                - minio
        topologyKey: kubernetes.io/hostname
    # SOFT preference: Spread across availability zones
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                  - minio
          topologyKey: topology.kubernetes.io/zone

# Node selection (optional)
nodeSelector: {}
  # node-role.kubernetes.io/storage: "true"

tolerations: []
  # - key: "storage"
  #   operator: "Equal"
  #   value: "true"
  #   effect: "NoSchedule"

# =============================================================================
# Ingress Configuration
# =============================================================================
ingress:
  # S3 API endpoint
  api:
    enabled: true
    className: "nginx"
    annotations:
      cert-manager.io/cluster-issuer: "letsencrypt-prod"
      nginx.ingress.kubernetes.io/proxy-body-size: "0"
      nginx.ingress.kubernetes.io/proxy-buffering: "off"
      nginx.ingress.kubernetes.io/proxy-request-buffering: "off"
      nginx.ingress.kubernetes.io/proxy-connect-timeout: "300"
      nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
      nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    hosts:
      - host: s3.example.com
        paths:
          - path: /
            pathType: Prefix
    tls:
      - secretName: minio-api-tls
        hosts:
          - s3.example.com

  # Web Console
  console:
    enabled: true
    className: "nginx"
    annotations:
      cert-manager.io/cluster-issuer: "letsencrypt-prod"
      nginx.ingress.kubernetes.io/proxy-buffering: "off"
    hosts:
      - host: minio-console.example.com
        paths:
          - path: /
            pathType: Prefix
    tls:
      - secretName: minio-console-tls
        hosts:
          - minio-console.example.com

# =============================================================================
# Monitoring Configuration
# =============================================================================
monitoring:
  enabled: true
  serviceMonitor:
    enabled: true
    namespace: ""  # Deploy in same namespace as MinIO
    labels:
      release: prometheus
    interval: 30s
    scrapeTimeout: 10s
    scheme: http

# =============================================================================
# Network Policy
# =============================================================================
networkPolicy:
  enabled: true
  ingress:
    api:
      from:
        # Allow from ingress controller
        - namespaceSelector:
            matchLabels:
              name: ingress-nginx
        # Allow from application namespace
        - namespaceSelector:
            matchLabels:
              name: applications
    console:
      from:
        - namespaceSelector:
            matchLabels:
              name: ingress-nginx
  egress:
    extraRules:
      # Allow Prometheus metrics push
      - to:
          - namespaceSelector:
              matchLabels:
                name: monitoring
        ports:
          - protocol: TCP
            port: 9090
      # Allow HTTPS for external connections
      - to:
          - namespaceSelector: {}
        ports:
          - protocol: TCP
            port: 443

# =============================================================================
# Security Configuration
# =============================================================================
serviceAccount:
  create: true
  automount: true
  annotations: {}
  name: ""

podSecurityContext:
  fsGroup: 1000
  runAsUser: 1000
  runAsGroup: 1000
  fsGroupChangePolicy: "OnRootMismatch"

securityContext:
  runAsNonRoot: true
  runAsUser: 1000
  capabilities:
    drop:
      - ALL

# =============================================================================
# Pod Configuration
# =============================================================================
podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "9000"
  prometheus.io/path: "/minio/v2/metrics/cluster"

podLabels:
  environment: "production"

# =============================================================================
# Lifecycle Hooks
# =============================================================================
lifecycle:
  preStop:
    exec:
      command: ["/bin/sh", "-c", "sleep 15"]  # Graceful shutdown

# =============================================================================
# Advanced Configuration
# =============================================================================
# Init containers (optional)
initContainers: []
  # - name: init-chmod
  #   image: busybox:latest
  #   command: ['sh', '-c', 'for i in $(seq 0 3); do chown -R 1000:1000 /data$i; done']
  #   volumeMounts:
  #     - name: data-0
  #       mountPath: /data0
  #     - name: data-1
  #       mountPath: /data1
  #     - name: data-2
  #       mountPath: /data2
  #     - name: data-3
  #       mountPath: /data3

# Extra volumes and volume mounts
extraVolumes: []
extraVolumeMounts: []

# Extra environment variables
extraEnv: []
  # - name: MINIO_BROWSER_REDIRECT_URL
  #   value: "https://minio-console.example.com"

# =============================================================================
# Notes
# =============================================================================
# Production Recommendations:
# 1. Set strong rootPassword (min 8 characters, use secrets)
# 2. Use fast-ssd storage class with high IOPS
# 3. Configure ingress with TLS (cert-manager)
# 4. Enable monitoring and integrate with Prometheus
# 5. Set up regular backups using MinIO's replication
# 6. Configure bucket lifecycle policies for data retention
# 7. Use distributed mode (4+ nodes) for production HA
# 8. Ensure total drives (replicaCount * drivesPerNode) is even
# 9. Monitor disk usage and set up alerts
# 10. Configure network policies for security
#
# Erasure Coding:
# - 4 nodes × 4 drives = 16 drives total
# - EC:4 configuration provides fault tolerance for 4 drive failures
# - Usable capacity ≈ 75% of total storage (4TB usable from 16 × 500GB)
#
# Scaling Considerations:
# - Cannot scale down distributed mode below initial replica count
# - Can scale up in increments matching drive configuration
# - Example: 4 nodes → 8 nodes (add 4 nodes with 4 drives each)
