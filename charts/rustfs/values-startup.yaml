# Startup / SMB optimized configuration for RustFS
# Target: 10K users, production-ready S3 alternative
#
# Key features:
# - High availability (4 replicas)
# - SSD + HDD tiered storage
# - Production monitoring enabled
# - Network policies for security
# - Autoscaling up to 10 replicas
# - Enterprise-grade resource allocation
#
# Estimated capacity:
# - Hot tier (SSD): 200Gi (50Gi x 2 dirs x 2 replicas)
# - Cold tier (HDD): 4Ti (500Gi x 2 dirs x 4 replicas)
# - Total: ~4.2Ti
#
# Usage:
#   helm install rustfs ./charts/rustfs -f charts/rustfs/values-startup.yaml

# RustFS configuration
rustfs:
  # CRITICAL: Change these immediately!
  rootUser: "admin"
  rootPassword: ""  # REQUIRED - Set via --set or secret

  region: "production"
  consolePort: 9001
  apiPort: 9000

  # Multi-drive configuration (4 dirs per replica)
  dataDirs: 4

  extraEnv:
    # Optimize for concurrent connections
    - name: RUSTFS_API_REQUESTS_MAX
      value: "10000"
    - name: RUSTFS_API_REQUESTS_DEADLINE
      value: "10s"

  args: []

# Persistence - Production-grade storage
persistence:
  enabled: true

  # Default storage class (can be overridden by storageTiers)
  storageClass: "fast-ssd"  # Adjust to your cloud provider

  accessMode: ReadWriteOnce

  # Base size (overridden by storageTiers)
  size: 100Gi

  # Retain for data safety
  reclaimPolicy: Retain

  existingClaim: ""
  annotations: {}

# Tiered storage for cost optimization
# Hot tier: Frequently accessed data (SSD)
# Cold tier: Archive/backup data (HDD)
storageTiers:
  enabled: true

  hot:
    storageClass: "fast-ssd"    # AWS: gp3, GCP: pd-ssd, Azure: Premium_LRS
    size: 50Gi
    dataDirs: 2                 # 2 hot dirs per pod

  cold:
    storageClass: "standard-hdd" # AWS: st1, GCP: pd-standard, Azure: Standard_LRS
    size: 500Gi
    dataDirs: 2                 # 2 cold dirs per pod

# High availability cluster (4 nodes minimum recommended)
replicaCount: 4

# Container image
image:
  repository: rustfs/rustfs
  pullPolicy: IfNotPresent
  tag: "1.0.0-alpha.66"

imagePullSecrets: []

nameOverride: ""
fullnameOverride: ""

# Service account with RBAC
serviceAccount:
  create: true
  automount: true
  annotations: {}
  name: ""

podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "9000"
  prometheus.io/path: "/metrics"

podLabels:
  environment: production
  tier: storage

# Security context
podSecurityContext:
  fsGroup: 1000
  fsGroupChangePolicy: "OnRootMismatch"

securityContext:
  runAsUser: 1000
  runAsGroup: 1000
  runAsNonRoot: true
  readOnlyRootFilesystem: false
  capabilities:
    drop:
      - ALL

# Service - LoadBalancer for production
service:
  type: LoadBalancer  # Use ClusterIP + Ingress for cost savings

  api:
    port: 9000
    targetPort: 9000
    nodePort: null

  console:
    port: 9001
    targetPort: 9001
    nodePort: null

  annotations:
    # AWS Network Load Balancer
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"
    # GCP Load Balancer
    # cloud.google.com/load-balancer-type: "Internal"
    # Azure Load Balancer
    # service.beta.kubernetes.io/azure-load-balancer-internal: "true"

# Headless service for StatefulSet clustering
headlessService:
  enabled: true

# Ingress for production with TLS
ingress:
  enabled: true
  className: "nginx"  # or "traefik"

  annotations:
    # Session affinity for multi-part uploads
    nginx.ingress.kubernetes.io/affinity: "cookie"
    nginx.ingress.kubernetes.io/session-cookie-name: "rustfs-route"
    nginx.ingress.kubernetes.io/session-cookie-hash: "sha1"
    # Large file upload support
    nginx.ingress.kubernetes.io/proxy-body-size: "0"
    nginx.ingress.kubernetes.io/proxy-request-buffering: "off"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
    # TLS
    cert-manager.io/cluster-issuer: "letsencrypt-prod"

  api:
    enabled: true
    hosts:
      - host: s3.yourdomain.com
        paths:
          - path: /
            pathType: Prefix
    tls:
      - secretName: rustfs-api-tls
        hosts:
          - s3.yourdomain.com

  console:
    enabled: true
    hosts:
      - host: console.s3.yourdomain.com
        paths:
          - path: /
            pathType: Prefix
    tls:
      - secretName: rustfs-console-tls
        hosts:
          - console.s3.yourdomain.com

# Resource limits - Production-grade (10K users)
# Estimated load: 1000 req/s, 100GB/day ingress
resources:
  limits:
    cpu: 4000m      # 4 CPU cores
    memory: 8Gi     # 8GB RAM
  requests:
    cpu: 2000m      # 2 CPU cores baseline
    memory: 4Gi     # 4GB RAM baseline

# Health probes - Production timings
livenessProbe:
  httpGet:
    path: /rustfs/health/live
    port: api
  initialDelaySeconds: 60
  periodSeconds: 30
  timeoutSeconds: 10
  failureThreshold: 5
  successThreshold: 1

readinessProbe:
  httpGet:
    path: /rustfs/health/ready
    port: api
  initialDelaySeconds: 30
  periodSeconds: 15
  timeoutSeconds: 10
  failureThreshold: 3
  successThreshold: 1

startupProbe:
  httpGet:
    path: /rustfs/health/live
    port: api
  initialDelaySeconds: 0
  periodSeconds: 10
  timeoutSeconds: 10
  failureThreshold: 30
  successThreshold: 1

# Autoscaling for traffic spikes
autoscaling:
  enabled: true
  minReplicas: 4
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

# PodDisruptionBudget - Ensure 3/4 pods always available
podDisruptionBudget:
  enabled: true
  minAvailable: 3  # Keep 75% availability during updates

# NetworkPolicy - Restrict traffic
networkPolicy:
  enabled: true
  ingress:
    # Allow Ingress controller
    - from:
      - namespaceSelector:
          matchLabels:
            name: ingress-nginx
      ports:
        - protocol: TCP
          port: 9000
        - protocol: TCP
          port: 9001
    # Allow pod-to-pod (clustering)
    - from:
      - podSelector:
          matchLabels:
            app.kubernetes.io/name: rustfs
      ports:
        - protocol: TCP
          port: 9000
  egress:
    # Allow DNS
    - to:
      - namespaceSelector: {}
        podSelector:
          matchLabels:
            k8s-app: kube-dns
      ports:
        - protocol: UDP
          port: 53
    # Allow pod-to-pod
    - to:
      - podSelector:
          matchLabels:
            app.kubernetes.io/name: rustfs
      ports:
        - protocol: TCP
          port: 9000

# Monitoring - Production observability
monitoring:
  enabled: true
  serviceMonitor:
    enabled: true
    interval: 30s
    labels:
      prometheus: kube-prometheus
    path: /metrics
    port: api

# Node selector - Use SSD nodes for hot tier
nodeSelector:
  node.kubernetes.io/instance-type: "c5.2xlarge"  # AWS example
  # disktype: ssd  # Custom label

# Tolerations - Allow scheduling on dedicated storage nodes
tolerations:
  - key: "storage-node"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"

# Affinity - Distribute pods across availability zones
affinity:
  podAntiAffinity:
    # Hard requirement: Don't schedule on same node
    requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/name: rustfs
        topologyKey: kubernetes.io/hostname
    # Soft preference: Spread across zones
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app.kubernetes.io/name: rustfs
          topologyKey: topology.kubernetes.io/zone

extraEnvFrom: []
extraVolumes: []
extraVolumeMounts: []

# Init containers - Production readiness checks
initContainers:
  - name: check-storage
    image: busybox:1.36
    command:
      - sh
      - -c
      - |
        echo "Checking storage mount points..."
        for dir in /data/hot-0 /data/hot-1 /data/cold-0 /data/cold-1; do
          if [ ! -d "$dir" ]; then
            echo "ERROR: $dir not mounted!"
            exit 1
          fi
          echo "âœ“ $dir mounted successfully"
        done
        echo "All storage checks passed!"
    volumeMounts:
      - name: hot-0
        mountPath: /data/hot-0
      - name: hot-1
        mountPath: /data/hot-1
      - name: cold-0
        mountPath: /data/cold-0
      - name: cold-1
        mountPath: /data/cold-1

# Lifecycle - Graceful shutdown for in-flight uploads
lifecycle:
  preStop:
    exec:
      command:
        - /bin/sh
        - -c
        - |
          echo "Shutting down gracefully..."
          sleep 30

# Update strategy - Gradual rollout
updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    partition: 0  # Update all pods (set to N to keep N pods on old version)

# Pod management - Sequential for safe cluster updates
podManagementPolicy: OrderedReady
